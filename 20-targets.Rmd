# Organiser ses traitements avec `targets`

[targets](https://docs.ropensci.org/targets/) est une extension R développée par [Will Landau](https://twitter.com/wmlandau) qui permet d'organiser un projet sous la forme d'un *pipeline* de traitements^[Pour les personnes habituées au développement, il s'agit d'un équivalent à [GNU Make](https://www.gnu.org/software/make/) pour R.]. Cette organisation a plusieurs avantages :

- elle permet une description de toutes les étapes du *pipeline* dans un fichier dédié, et force à séparer ces différentes étapes dans des fonctions à part, ce qui facilite la lisibilité et la maintenance du projet
- elle facilite la reproductibilité des traitements, car elle garantit que toutes les étapes ont bien été effectuées dans le bon ordre et dans un nouvel environnement
- elle optimise les temps de calcul, car en cas de une modification seules les étapes qui le nécessitent sont relancées

L'utilisation de `targets` dans des petits projets peut être vue comme une complexité supplémentaire pas toujours très utile, mais elle peut être très bénéfique pour des projets plus complexes ou comportant des temps de calculs importants à certaines étapes.


## Définition du pipeline

```{r, message=FALSE, warning=FALSE, echo=FALSE, cache=FALSE, eval=TRUE}
library(targets)

# On se place à la racine du projet d'exemple
knitr::opts_knit$set(root.dir = "resources/targets_sample_project/")
options(crayon.enabled = FALSE)
```

```{r cache=FALSE, echo=FALSE, include=FALSE}
# On supprime le cache
targets::tar_destroy("all")
```


### Projet d'exemple

```{r cache=FALSE, echo=FALSE, include=FALSE}
targets_content <- readLines("_targets.R", encoding = "UTF-8")
file.rename("_targets.R", "_targets.R.orig")

targets_content <- targets_content %>%
    discard(~str_detect(.x, "# Génération rapport")) %>%
    discard(~str_detect(.x, "tar_render")) %>%
    str_replace_all(fixed("calcule_evo(min_n = 1000),"), "calcule_evo(min_n = 1000)")
writeLines(targets_content, "_targets.R")

calculs_content <- readLines("R/fonctions_calculs.R", encoding = "UTF-8")
file.rename("R/fonctions_calculs.R", "R/fonctions_calculs.R.orig")

calculs_content <- calculs_content %>%
        str_replace_all(fixed("round(evo / `2019` * 100, 1)"), "round(evo / `2019` * 100, 2)")
writeLines(calculs_content, "R/fonctions_calculs.R")
```

Pour illustrer la suite nous allons partir d'un projet très simple : à partir du [fichier national des prénoms donnés à la naissance](https://www.insee.fr/fr/statistiques/2540004), diffusé par l'INSEE, on souhaite produire un document indiquant les prénoms ayant les évolutions les plus fortes (à la hausse ou à la baisse) entre 2019 et 2020.

Le dossier de notre projet s'organise de la manière suivante :

```
data/
└── nat2020.csv
R/
├── fonctions_recode.R
└── fonctions_calculs.R
_targets.R
```

```{block type='rmdnote'}
À noter que `targets` n'impose aucune structure de projet particulière en-dehors de la présence du fichier `_targets.R`. On aurait donc pu avoir une organisation tout à fait différente.
```

Le fichier `data/nat2020.csv` contient les données brutes téléchargées depuis le site de l'INSEE.

Le fichier `R/fonctions_recode.R` contient deux fonctions de traitement et de remise en forme des données.

```{r eval=FALSE, code=readLines('resources/targets_sample_project/R/fonctions_recode.R')}
```

Le fichier `R/fonctions_calculs.R` contient une seule fonction qui calcule les variables d'évolution 2019-2020.

```{r eval=FALSE, cache=FALSE, code=readLines('resources/targets_sample_project/R/fonctions_calculs.R')}
```


### `_targets.R`

C'est dans le fichier `_targets.R`, situé à la racine du dossier, qu'on va définir le *pipeline* constitué de toutes les étapes de notre traitement : chargement et manipulation des données, calculs, génération de rapports, etc. Ces étapes sont également appelées *cibles* (*targets*).

```{block type='rmdnote'}
La syntaxe présentée ici est celle proposée par l'extension `tarchetypes`, qui est un peu plus facile à prendre en main et plus lisible que la syntaxe native de `targets`.
```

Le fichier `_targets.R` commence par charger à la fois `targets` et `tarchetypes`.

```{r eval=FALSE}
# Packages nécessaires pour ce script
library(targets)
library(tarchetypes)
```

On va ensuite utiliser `source()` pour charger le contenu des deux fichiers `R/fonctions_recode.R` et `R/fonctions_calculs.R`, pour pouvoir utiliser par la suite les fonctions qu'ils définissent.

```{r eval=FALSE}
# Chargement des fonctions
source("R/fonctions_recode.R")
source("R/fonctions_calculs.R")
```

On définit ensuite des options globales pour notre *pipeline*. L'option `packages` de `tar_option_set()`, permet de spécifier une liste d'extensions à charger systématiquement avant le lancement de chaque étape du *pipeline*. Ici on s'assure que l'extension `tidyverse` est bien chargée et disponible.

```{r eval=FALSE}
# Options pour les différentes étapes
options(tidyverse.quiet = TRUE)
tar_option_set(packages = "tidyverse")
```

Vient enfin la définition de notre *pipeline* proprement dit. Celle-ci se fait via la fonction `tar_plan()` de `tarchetypes`.

La première opération que l'on souhaite effectuer est de charger les données contenues dans `data/nat2020.csv`. Pour cela on va d'abord créer une première étape de *pipeline* qui consiste à *référencer* notre fichier CSV à l'aide de la fonction `tar_file()`.

```{r eval=FALSE}
tar_plan(
    # Chargement du fichier CSV
    tar_file(csv_file, "data/nat2020.csv")
)
```

Cette première étape définit une *cible* (*target*), nommée `csv_file`, qui pointe vers notre fichier CSV.

On ajoute une seconde étape qui charge les données à l'aide de `read_csv2()`. 

```{r eval=FALSE}
tar_plan(
    # Chargement du fichier CSV
    tar_file(csv_file, "data/nat2020.csv"),
    donnees_brutes = read_csv2(csv_file),
)
```

Cette étape définit une nouvelle cible nommée `donnees_brutes`. Cette cible correspond au nom d'une étape, mais aussi à un objet : dans ce qui suit, `donnees_brutes` correspond au tableau de données résultat du `read_csv2()`.

On va utiliser cet objet dans une troisième étape qui lui applique nos deux fonctions de filtrage et transformation définies dans `R/fonctions_recode.R`.

```{r eval=FALSE}
tar_plan(
    # Chargement du fichier CSV
    tar_file(csv_file, "data/nat2020.csv"),
    donnees_brutes = read_csv2(csv_file),

    # Mise en forme des données
    donnees = donnees_brutes %>%
        filter_data() %>%
        pivot_2019_2020()
)
```

Ici aussi, `donnees` est à la fois le nom d'une cible et un objet contenant nos données retravaillées. On utilise cet objet dans une nouvelle étape qui utilise la fonction de `R/fonctions_calculs.R` pour calculer les variables d'évolution.

```{r eval=FALSE}
tar_plan(
    # Chargement du fichier CSV
    tar_file(csv_file, "data/nat2020.csv"),
    donnees_brutes = read_csv2(csv_file),

    # Mise en forme des données
    donnees = donnees_brutes %>%
        filter_data() %>%
        pivot_2019_2020(),

    # Calcul indicateurs
    donnees_evo = donnees %>%
        calcule_evo(min_n = 1000)
)
```

```{block type='rmdnote'}
`targets` offre aussi la possibilité de définir notre *pipeline* directement dans un fichier RMarkdown, ce qui peut permettre notamment de mieux le documenter. Pour plus d'information on pourra se référer au chapitre [Target Markdown](https://books.ropensci.org/targets/markdown.html) du manuel en ligne.
```

Au final, notre fichier `_targets.R` est donc le suivant :

```{r eval=FALSE, code=readLines('resources/targets_sample_project/_targets.R'), cache=FALSE}
```

## Exécution du pipeline

Une fois défini, `targets` fournit des outils permettant de visualiser la structure de notre pipeline et son état.

```{r cache=FALSE}
tar_visnetwork()
```

Les différentes cibles apparaissent sous forme de cercles, tandis que les fonctions qui leur sont appliquées sont symbolisées par des triangles. Les flèches montrent que `targets` a créé un réseau de *dépendances* entre cibles et fonctions, ainsi la cible `donnees` dépend des fonctions `filter_data`, `pivot_2019_2020` et de la cible `donnees_brutes`, qui elle-même dépend de la cible `csv_file`.

La couleur des différents éléments montrent que ceux-ci sont à l'état *outdated* : ils ne sont pas à jour.

On va donc exécuter notre pipeline, en utilisant la fonction `tar_make()`.

```{r cache=FALSE}
tar_make()
```

Lorsqu'on utilise `tar_make()`, `targets` va lancer une nouvelle session R (pour éviter tout problème lié à l'état de notre session actuelle), charger les extensions définie via `tar_option_set()`, et exécuter les cibles définies avec `tar_plan()`.

On peut visualiser à nouveau l'état de notre pipeline.

```{r cache=FALSE}
tar_visnetwork()
```

On voit que toutes les cibles sont passées à l'état *up to date*.

À chaque étape, `targets` a créé et stocké dans un cache chacun des objets correspondants aux différentes cibles (`donnees_brutes`, `donnees`, etc.). On peut charger et ces objets dans notre session avec la fonction `tar_load()`^[Ces données sont stockées dans le répertoire `_targets` à la racine du projet.].

```{r}
tar_load(donnees_evo)
donnees_evo
```

On peut aussi utiliser `tar_read()`, qui lit et retourne les résultats d'une des cibles, permettant de les stocker dans un nouvel objet.

```{r}
evo <- tar_read(donnees_evo)
```


## Modification du pipeline

Essayons de lancer à nouveau notre pipeline :

```{r cache=FALSE}
tar_make()
```

On voit que toutes les cibles ont été "skippées" : quand on lance `tar_make()`, seules les cibles qui sont à l'état *outdated* sont recalculées. Les résultats des autres sont conservés tels quels.

On va maintenant modifier légèrement notre fichier `R/fonctions_calculs.R` : plutôt que d'arrondir les évolutions en pourcentages à deux décimale, on n'en conserve plus qu'une.

```{r echo=FALSE, include=FALSE, cache=FALSE}
file.remove("R/fonctions_calculs.R")
file.rename("R/fonctions_calculs.R.orig", "R/fonctions_calculs.R")
```

```{r eval=FALSE, cache=FALSE, code=readLines('resources/targets_sample_project/R/fonctions_calculs.R')}
```

On visualise à nouveau l'état de notre pipeline :

```{r cache=FALSE}
tar_visnetwork()
```

Grâce à sa gestion interne des dépendances entre les cibles, `targets` voit que la fonction `calcule_evo` a été modifiée (elle est passée en statut *outdated*), et comme la cible `donnees_evo` dépend de cette fonction, celle-ci a également placée en *outdated*. On peut obtenir directement une liste des cibles qui ne sont plus à jour à l'aide de la fonction `tar_outdated()` :

```{r cache=FALSE}
tar_outdated()
```

On relance notre pipeline :

```{r cache=FALSE}
tar_make()
```

On voit que les cibles `csv_file`, `donnees_brutes` et `donnees` ont été "skippées", `targets` est allé prendre directement leurs valeurs déjà stockées en cache. Par contre `donnees_evo` a bien été recalculée.

On peut vérifier que notre pipeline est désormais entièrement à jour :

```{r cache=FALSE}
tar_visnetwork()
```

```{block type='rmdnote'}
À noter que `targets` gère aussi les modifications des fichiers externes. Ainsi, si on modifie le contenu de `nat2020.csv`, la cible `csv_file` passerait en *outdated*, tout comme l'ensemble des autres cibles puisqu'elles dépendent directement ou indirectement de celle-ci. Dans ce cas, un `tar_make()` aurait pour effet de recalculer l'intégralité du pipeline.
```


## RMarkdown

```{r cache=FALSE, echo=FALSE, include=FALSE}
# Retour aux fichiers d'origine
file.remove("_targets.R")
file.rename("_targets.R.orig", "_targets.R")
```

Imaginons maintenant qu'on souhaite générer un rapport à partir d'un document RMarkdown en utilisant les données d'évolution calculées par notre pipeline. On crée donc un nouveau fichier `evolution.Rmd` dans un dossier `reports`.

```
data/
└── nat2020.csv
R/
├── fonctions_recode.R
└── fonctions_calculs.R
reports/
└── evolution.Rmd
_targets.R
```

Quand on utilise un document RMarkdown dans un pipeline, il faut faire attention de bien accéder aux données utilisées via les fonctions `tar_read()` ou `tar_load()` : ceci permet de s'assurer qu'on récupère les données "à jour", et cela permet aussi à `targets` de déterminer un lien de dépendance entre le document et les données.

Comme on souhaite utiliser les données de `donnees_evo`, on devra donc utiliser quelque chose comme :

```{r eval=FALSE}
d <- tar_read(donnees_evo)
```

Au final, le contenu de notre fichier RMarkdown est le suivant :

```{r echo=FALSE, comment=""}
cat(htmltools::includeText("reports/evolution.Rmd"))
```

Pour ajouter ce rapport à notre pipeline, il suffit de créer une nouvelle cible dans `_targets.R` en utilisant la fonction `tar_render()`.

```{r cache=FALSE, eval=FALSE, code=readLines("resources/targets_sample_project/_targets.R")}
```


Visualisons notre pipeline modifié :

```{r cache=FALSE}
tar_visnetwork()
```

On voit que notre nouvelle cible `report_evo` a bien été prise en compte, qu'elle dépend bien de `donnees_evo` et qu'elle est à l'état *outdated*. 

Si on exécute notre pipeline :

```{r cache=FALSE}
tar_make()
```

On voit que la cible `report_evo` a bien été calculée, et on devrait retrouver notre rapport compilé au format HTML dans le dossier `reports`.


## Gestion des données en cache

tar_delete()
tar_destroy("all")

## Avantages et inconvénients

## Ressources

Nous n'avons vu ici qu'un petit aperçu des fonctionnalités de `targets`, qui propose 

https://docs.ropensci.org/targets

https://milesmcbain.xyz/the-drake-post/

https://books.ropensci.org/targets/

